07Oct21

WORK ON CONTROLLER.PY READING OUTPUT FROM BATCH
# Tried using the return feature from os.system or subprocess however the batch ticket will always return 0 because it only calls the ticket
# Can use #SBATCH --wait to wait until node is done running, but then python needs to call the libraries async. Seems complicated.

# Want to output into slurm-*.out with #NGSF tag so that can call "egrep "^NGSF" -" to pull all the info.
# However I need the JobID. Stored as $SLURM_JOBID, but how do I get it without the initial job id?
# "$egrep "^NGSF" slurm-*.out" will call the information for every out file. Could use that but would need to clear all .out files if a run fails. Additionally would have to sort based on JobID after.

# PULL FROM sq?
# Can run "squeue" with account flag and generate a txt list. However will generate a list of every job including others. Also not really usable by other people.

# Can get a list of all active "pipe_RNA" jobs on the clutser using controller.get_jobIDs
# Can use this list to check slurm-*.out files now by replacing with 


23Oct21
VIRUTALENV
$ source ~/cluster/pipe_RNA/pipe_control/pipe_RNA/bin/activate

Created job_list variable to track all jobs

Created checks.py to contain all the checking scripst
-> Checks to ensure the run has started.
-> Also will return the library ID number.

Main controller script will now begin checking as run continues
-> Future work will be to move onto fastp and fastqc
-> Long term work will be to figure out timing and async abilities of checking 

Combine check updated
- Checks for end of 4-lane comining step
- Pulls read1 and read2 counts
? Is time delay best way to recheck the code?
? QC checks here?
> Next to get fastp working

25Oct21
Began trying to get fastp to work
Will need to use wget to download and install everytime
However fastqc is an available module. Will begin using this

?Should we get fastp as an available module?
? Fastqc seems to have less options available

26Oct21
Austin suggested copying fastp from datastore onto every node.
batch_pipe_RNAseq script now does that properly.

- Need to confirm that it functions properly.
- Need to confirm that report files are output

Controller.py creates directories for data output
Fastp accepts the fastq files, and produces the correct output! Seems to be working thus far

WHAT TO DO WITH UNPAIRED?

Sometimes when I run it assigns me the job number, but for an already existing job. i.e. 234050. Then my script fails immediately. Re-try and gives me 234052. Same pmb399 user. Again with 234053. 

WORKING AT FINE TUNING THE PATHWAYS FOR STAR
PENDING IS CANCELLING MY RUNS


27Oct21
Fastp is a cluster-specific module
> Now loads module rather than copying application from datastore

If a run is pending, it does not create a slurm.out. Therefore when it tries to confirm the run has started by looking at the slurm.out, then the run fails and cancels. To get around this, I need to check for pending.
Changes to get_jobIDs()
Use squeue to checking for any pending jobs with NGSF_RNA name. Waits until all runs have started before getting jobIDs. 

29Oct21
Script runs completely through STAR and outputs correct files.
However files are not rsynced back to the correct area. In fact, I don't know where they end up.
? How to adjust the path for the files to be sent back to the directory where the controller.py was called?
? os.getcwd() passed into batch_pipe_RNAseq?
? Do I add library IDs to the outputfiles? Like R2100207_Aligned.sortedbyCoord.bam.out

? Output directory should change each call to prevent clobber

02Nov21
Adding outdir passing into the batch script by using os.getcwd()
? Need to figure that outdir clobber issue - use a time or jobID? or a job name? but needed to change to pass?

? The next question is what happens to a job that finishes while python script is cancelled? Need the computer still be run.

04Nov21

Successfully completes the alignment on the node and returns all the results.
Closed down the application during the run, and the node kept running. Not sure what that means for the Python script yet.

Do I even need to create a python environment because everything is a module?
Two libraries Successfully ran and transfered to a unique directory created each time. 
Is VIRUTALENV necessary?


05Nov21
Working on adding htseq functionality to the pipeline. Htseq was installed using pip on an empty venv (py3.8.5).
Error keeps coming up
$ htseq-count
Traceback (most recent call last):
  File "/globalhome/arb594/HPC/cluster/pipe_RNA/pipe_control/htseq_batch/lib/python3.8/site-packages/numpy/core/__init__.py", line 22, in <module>
    from . import multiarray
  File "/globalhome/arb594/HPC/cluster/pipe_RNA/pipe_control/htseq_batch/lib/python3.8/site-packages/numpy/core/multiarray.py", line 12, in <module>
    from . import overrides
  File "/globalhome/arb594/HPC/cluster/pipe_RNA/pipe_control/htseq_batch/lib/python3.8/site-packages/numpy/core/overrides.py", line 7, in <module>
    from numpy.core._multiarray_umath import (
ImportError: libgfortran.so.5: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/globalhome/arb594/HPC/cluster/pipe_RNA/pipe_control/htseq_batch/bin/htseq-count", line 3, in <module>
    import HTSeq.scripts.count
  File "/globalhome/arb594/HPC/cluster/pipe_RNA/pipe_control/htseq_batch/lib/python3.8/site-packages/HTSeq/__init__.py", line 13, in <module>
    from HTSeq._HTSeq import *
  File "src/HTSeq/_HTSeq.pyx", line 1, in init HTSeq._HTSeq
  File "/globalhome/arb594/HPC/cluster/pipe_RNA/pipe_control/htseq_batch/lib/python3.8/site-packages/numpy/__init__.py", line 150, in <module>
    from . import core
  File "/globalhome/arb594/HPC/cluster/pipe_RNA/pipe_control/htseq_batch/lib/python3.8/site-packages/numpy/core/__init__.py", line 48, in <module>
    raise ImportError(msg)
ImportError: 

IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!

Importing the numpy C-extensions failed. This error can happen for
many reasons, often due to issues with your setup or how NumPy was
installed.

We have compiled some common reasons and troubleshooting tips at:

    https://numpy.org/devdocs/user/troubleshooting-importerror.html

Please note and check the following:

  * The Python version is: Python3.8 from "/globalhome/arb594/HPC/cluster/pipe_RNA/pipe_control/htseq_batch/bin/python"
  * The NumPy version is: "1.21.2"

and make sure that they are the versions you expect.
Please carefully study the documentation linked above for further help.

Original error was: libgfortran.so.5: cannot open shared object file: No such file or directory

htseq count runs on the node for some reasons
what gtf to use


08Nov21

52mil reads
What time to use?
Lane combine = 2min
Fastp = 10min
STAR = 20min
HTSeq = 60min

Adjusting time of batch run to 2h, but tracking HTseq time
? Will need a way to adjust for time reservations in the future?

26Nov21
Working on deseq2_htseq.R script incorpation.

Use /datastore/NGSF001/projects/21-1ELSI-001/dge as template for sample and condition files
Lines 53, 54, 56, and 60 need to be manually edited in each experiment
Include a method to add this data to .json, have python convert to text for .R, and then delete those files afterwards

Current directory structure has each library in one directory
May need to modify that so make .R script run on all htseq.count documents in a single directory.
_data
|__R2100027
_stats
|__htseq


20Dec21
Modified so that all input data comes from the single json.
Json data is processed in get_args() stored in global variable "paths". This data can now be accessed by call_bath_runs() and call_deseq2()

Created analysis_directory_setup()
Goal is to create a new folder within the run folder for "expression" analysis, while collapsing all the data into an "alignments" directory
_alignments
|__R2100027
_expression
|_whatever the deseq2_htseq output is


22Dec21
Installing rpy2 to port DEseq2 in conda environment "diffexpr"
https://github.com/wckdouglas/diffexpr

Need to download install files still

23Dec21
Install files located at /datastore/NGSF001/software/src/diffexpr/diffexpr-master